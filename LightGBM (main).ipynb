{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHnrTvNEj26G"
      },
      "source": [
        "**SINGLE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LgfmoJ7Pj2C8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (1.2.8)\n",
            "Requirement already satisfied: lightgbm in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (4.6.0)\n",
            "Requirement already satisfied: graphviz in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from catboost) (3.9.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from catboost) (6.1.1)\n",
            "Requirement already satisfied: six in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages (from plotly->catboost) (1.40.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pslist.nproc</th>\n",
              "      <th>pslist.nppid</th>\n",
              "      <th>pslist.avg_threads</th>\n",
              "      <th>pslist.nprocs64bit</th>\n",
              "      <th>pslist.avg_handlers</th>\n",
              "      <th>dlllist.ndlls</th>\n",
              "      <th>dlllist.avg_dlls_per_proc</th>\n",
              "      <th>handles.nhandles</th>\n",
              "      <th>handles.avg_handles_per_proc</th>\n",
              "      <th>handles.nport</th>\n",
              "      <th>...</th>\n",
              "      <th>svcscan.nservices</th>\n",
              "      <th>svcscan.kernel_drivers</th>\n",
              "      <th>svcscan.fs_drivers</th>\n",
              "      <th>svcscan.process_services</th>\n",
              "      <th>svcscan.shared_process_services</th>\n",
              "      <th>svcscan.interactive_process_services</th>\n",
              "      <th>svcscan.nactive</th>\n",
              "      <th>callbacks.ncallbacks</th>\n",
              "      <th>callbacks.nanonymous</th>\n",
              "      <th>callbacks.ngeneric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>17</td>\n",
              "      <td>10.555556</td>\n",
              "      <td>0</td>\n",
              "      <td>202.844444</td>\n",
              "      <td>1694</td>\n",
              "      <td>38.500000</td>\n",
              "      <td>9129</td>\n",
              "      <td>212.302326</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>389</td>\n",
              "      <td>221</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>121</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>19</td>\n",
              "      <td>11.531915</td>\n",
              "      <td>0</td>\n",
              "      <td>242.234043</td>\n",
              "      <td>2074</td>\n",
              "      <td>44.127660</td>\n",
              "      <td>11385</td>\n",
              "      <td>242.234043</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>392</td>\n",
              "      <td>222</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40</td>\n",
              "      <td>14</td>\n",
              "      <td>14.725000</td>\n",
              "      <td>0</td>\n",
              "      <td>288.225000</td>\n",
              "      <td>1932</td>\n",
              "      <td>48.300000</td>\n",
              "      <td>11529</td>\n",
              "      <td>288.225000</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>395</td>\n",
              "      <td>222</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32</td>\n",
              "      <td>13</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>264.281250</td>\n",
              "      <td>1445</td>\n",
              "      <td>45.156250</td>\n",
              "      <td>8457</td>\n",
              "      <td>264.281250</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>395</td>\n",
              "      <td>222</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>16</td>\n",
              "      <td>11.452381</td>\n",
              "      <td>0</td>\n",
              "      <td>281.333333</td>\n",
              "      <td>2067</td>\n",
              "      <td>49.214286</td>\n",
              "      <td>11816</td>\n",
              "      <td>281.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>392</td>\n",
              "      <td>222</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>124</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pslist.nproc  pslist.nppid  pslist.avg_threads  pslist.nprocs64bit  \\\n",
              "0            45            17           10.555556                   0   \n",
              "1            47            19           11.531915                   0   \n",
              "2            40            14           14.725000                   0   \n",
              "3            32            13           13.500000                   0   \n",
              "4            42            16           11.452381                   0   \n",
              "\n",
              "   pslist.avg_handlers  dlllist.ndlls  dlllist.avg_dlls_per_proc  \\\n",
              "0           202.844444           1694                  38.500000   \n",
              "1           242.234043           2074                  44.127660   \n",
              "2           288.225000           1932                  48.300000   \n",
              "3           264.281250           1445                  45.156250   \n",
              "4           281.333333           2067                  49.214286   \n",
              "\n",
              "   handles.nhandles  handles.avg_handles_per_proc  handles.nport  ...  \\\n",
              "0              9129                    212.302326              0  ...   \n",
              "1             11385                    242.234043              0  ...   \n",
              "2             11529                    288.225000              0  ...   \n",
              "3              8457                    264.281250              0  ...   \n",
              "4             11816                    281.333333              0  ...   \n",
              "\n",
              "   svcscan.nservices  svcscan.kernel_drivers  svcscan.fs_drivers  \\\n",
              "0                389                     221                  26   \n",
              "1                392                     222                  26   \n",
              "2                395                     222                  26   \n",
              "3                395                     222                  26   \n",
              "4                392                     222                  26   \n",
              "\n",
              "   svcscan.process_services  svcscan.shared_process_services  \\\n",
              "0                        24                              116   \n",
              "1                        24                              118   \n",
              "2                        27                              118   \n",
              "3                        27                              118   \n",
              "4                        24                              118   \n",
              "\n",
              "   svcscan.interactive_process_services  svcscan.nactive  \\\n",
              "0                                     0              121   \n",
              "1                                     0              122   \n",
              "2                                     0              120   \n",
              "3                                     0              120   \n",
              "4                                     0              124   \n",
              "\n",
              "   callbacks.ncallbacks  callbacks.nanonymous  callbacks.ngeneric  \n",
              "0                    87                     0                   8  \n",
              "1                    87                     0                   8  \n",
              "2                    88                     0                   8  \n",
              "3                    88                     0                   8  \n",
              "4                    87                     0                   8  \n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#For 16 class\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "mal_df = pd.read_csv(\"data.csv\")\n",
        "\n",
        "#For 15 class\n",
        "#mal_df = pd.read_csv(\"/content/drive/MyDrive/Research/DataseT/Malware_DataseT.csv\")\n",
        "\n",
        "#mal_df = mal_df.drop_duplicates()\n",
        "mal_df.shape\n",
        "\n",
        "mal_df['Class'].value_counts()\n",
        "mal_df.bfill(inplace=True)\n",
        "\n",
        "## Converting data types\n",
        "mal_df[\"Class\"] = mal_df[\"Class\"].astype(\"category\")\n",
        "\n",
        "y = mal_df[\"Class\"]\n",
        "X = mal_df.drop(columns=[\"Category\", \"Class\"])\n",
        "\n",
        "def category(column):\n",
        "  return column.split(\"-\")[0] if \"-\" in column else column\n",
        "\n",
        "def category_name(column):\n",
        "  return column.split(\"-\")[1] if \"-\" in column else column\n",
        "\n",
        "mal_df[\"category\"] = mal_df[\"Category\"].apply(category)\n",
        "\n",
        "mal_df[\"category\"].value_counts()\n",
        "\n",
        "# Creating a column with the names of the variants\n",
        "mal_df[\"category_name\"] = mal_df[\"Category\"].apply(category_name)\n",
        "mal_df[\"category_name\"].value_counts()\n",
        "\n",
        "X.head(5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category ['Benign' 'Ransomware' 'Spyware' 'Trojan']\n",
            "category_name ['180solutions' 'Ako' 'Benign' 'CWS' 'Conti' 'Emotet' 'Gator' 'Maze'\n",
            " 'Pysa' 'Reconyc' 'Refroso' 'Scar' 'Shade' 'TIBS' 'Transponder' 'Zeus']\n",
            "Class ['Benign' 'Malware']\n"
          ]
        }
      ],
      "source": [
        "# Define the label encoder\n",
        "def label_encoder(column):\n",
        "    lencode = LabelEncoder().fit(column)\n",
        "    print(column.name, lencode.classes_)\n",
        "    return lencode.transform(column)\n",
        "\n",
        "\n",
        "# Encoding the columns\n",
        "mal_df[\"category\"] = label_encoder(mal_df[\"category\"])\n",
        "mal_df[\"category_name\"] = label_encoder(mal_df[\"category_name\"])\n",
        "mal_df[\"class\"] = label_encoder(mal_df[\"Class\"])\n",
        "\n",
        "# Drop the Category and Class columns\n",
        "mal_df.drop([\"Category\", \"Class\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pslist.nproc</th>\n",
              "      <th>pslist.nppid</th>\n",
              "      <th>pslist.avg_threads</th>\n",
              "      <th>pslist.nprocs64bit</th>\n",
              "      <th>pslist.avg_handlers</th>\n",
              "      <th>dlllist.ndlls</th>\n",
              "      <th>dlllist.avg_dlls_per_proc</th>\n",
              "      <th>handles.nhandles</th>\n",
              "      <th>handles.avg_handles_per_proc</th>\n",
              "      <th>handles.nport</th>\n",
              "      <th>...</th>\n",
              "      <th>svcscan.nservices</th>\n",
              "      <th>svcscan.kernel_drivers</th>\n",
              "      <th>svcscan.fs_drivers</th>\n",
              "      <th>svcscan.process_services</th>\n",
              "      <th>svcscan.shared_process_services</th>\n",
              "      <th>svcscan.interactive_process_services</th>\n",
              "      <th>svcscan.nactive</th>\n",
              "      <th>callbacks.ncallbacks</th>\n",
              "      <th>callbacks.nanonymous</th>\n",
              "      <th>callbacks.ngeneric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>17</td>\n",
              "      <td>10.555556</td>\n",
              "      <td>0</td>\n",
              "      <td>202.844444</td>\n",
              "      <td>1694</td>\n",
              "      <td>38.500000</td>\n",
              "      <td>9129</td>\n",
              "      <td>212.302326</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>389</td>\n",
              "      <td>221</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>121</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>19</td>\n",
              "      <td>11.531915</td>\n",
              "      <td>0</td>\n",
              "      <td>242.234043</td>\n",
              "      <td>2074</td>\n",
              "      <td>44.127660</td>\n",
              "      <td>11385</td>\n",
              "      <td>242.234043</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>392</td>\n",
              "      <td>222</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40</td>\n",
              "      <td>14</td>\n",
              "      <td>14.725000</td>\n",
              "      <td>0</td>\n",
              "      <td>288.225000</td>\n",
              "      <td>1932</td>\n",
              "      <td>48.300000</td>\n",
              "      <td>11529</td>\n",
              "      <td>288.225000</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>395</td>\n",
              "      <td>222</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32</td>\n",
              "      <td>13</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>264.281250</td>\n",
              "      <td>1445</td>\n",
              "      <td>45.156250</td>\n",
              "      <td>8457</td>\n",
              "      <td>264.281250</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>395</td>\n",
              "      <td>222</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>16</td>\n",
              "      <td>11.452381</td>\n",
              "      <td>0</td>\n",
              "      <td>281.333333</td>\n",
              "      <td>2067</td>\n",
              "      <td>49.214286</td>\n",
              "      <td>11816</td>\n",
              "      <td>281.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>392</td>\n",
              "      <td>222</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>124</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pslist.nproc  pslist.nppid  pslist.avg_threads  pslist.nprocs64bit  \\\n",
              "0            45            17           10.555556                   0   \n",
              "1            47            19           11.531915                   0   \n",
              "2            40            14           14.725000                   0   \n",
              "3            32            13           13.500000                   0   \n",
              "4            42            16           11.452381                   0   \n",
              "\n",
              "   pslist.avg_handlers  dlllist.ndlls  dlllist.avg_dlls_per_proc  \\\n",
              "0           202.844444           1694                  38.500000   \n",
              "1           242.234043           2074                  44.127660   \n",
              "2           288.225000           1932                  48.300000   \n",
              "3           264.281250           1445                  45.156250   \n",
              "4           281.333333           2067                  49.214286   \n",
              "\n",
              "   handles.nhandles  handles.avg_handles_per_proc  handles.nport  ...  \\\n",
              "0              9129                    212.302326              0  ...   \n",
              "1             11385                    242.234043              0  ...   \n",
              "2             11529                    288.225000              0  ...   \n",
              "3              8457                    264.281250              0  ...   \n",
              "4             11816                    281.333333              0  ...   \n",
              "\n",
              "   svcscan.nservices  svcscan.kernel_drivers  svcscan.fs_drivers  \\\n",
              "0                389                     221                  26   \n",
              "1                392                     222                  26   \n",
              "2                395                     222                  26   \n",
              "3                395                     222                  26   \n",
              "4                392                     222                  26   \n",
              "\n",
              "   svcscan.process_services  svcscan.shared_process_services  \\\n",
              "0                        24                              116   \n",
              "1                        24                              118   \n",
              "2                        27                              118   \n",
              "3                        27                              118   \n",
              "4                        24                              118   \n",
              "\n",
              "   svcscan.interactive_process_services  svcscan.nactive  \\\n",
              "0                                     0              121   \n",
              "1                                     0              122   \n",
              "2                                     0              120   \n",
              "3                                     0              120   \n",
              "4                                     0              124   \n",
              "\n",
              "   callbacks.ncallbacks  callbacks.nanonymous  callbacks.ngeneric  \n",
              "0                    87                     0                   8  \n",
              "1                    87                     0                   8  \n",
              "2                    88                     0                   8  \n",
              "3                    88                     0                   8  \n",
              "4                    87                     0                   8  \n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Separate features and target\n",
        "X = mal_df.drop([\"category_name\", \"category\", \"class\"], axis=1)\n",
        "y = mal_df[\"category_name\"]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize all the classifiers for 16-class classification\n",
        "adaboost = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=20), n_estimators=50)\n",
        "logreg = LogisticRegression(penalty=\"l2\", C=10, max_iter=10000)\n",
        "svc = SVC(kernel=\"linear\", random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42, min_samples_leaf=10, min_samples_split=5)\n",
        "rf = RandomForestClassifier()\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\",objective=\"multi:softmax\", num_class=len(y.unique()), random_state=42)\n",
        "#xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "catboost = CatBoostClassifier(verbose=0)\n",
        "lightgbm = LGBMClassifier()\n",
        "\n",
        "# Create a list of tuples called classifiers which stores thee classifiers\n",
        "\n",
        "classifiers = [\n",
        "    (\"Adaboost\", adaboost),\n",
        "     (\"Logistic Regression\", logreg),\n",
        "    (\"Support Vector\", svc),\n",
        "    (\"Decision Tree\", dt),\n",
        "    (\"Random Forest\", rf),\n",
        "    (\"XGBoost\", xgb),\n",
        "    (\"CatBoost\", catboost),\n",
        "    (\"LightGBM\", lightgbm)\n",
        "]\n",
        "\n",
        "metrics_sbtsk3_cols = [\"Model Name\", \"Accuracy Score\", \"F1 Score\", \"Precision Score\", \"Recall Score\"]\n",
        "metrics_sbtsk3 = pd.DataFrame(columns=metrics_sbtsk3_cols)\n",
        "\n",
        "X.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lIHThGUHj2F6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Adaboost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.36      0.40       442\n",
            "           1       0.36      0.33      0.35       389\n",
            "           2       1.00      1.00      1.00      5790\n",
            "           3       0.40      0.38      0.39       401\n",
            "           4       0.44      0.40      0.42       408\n",
            "           5       0.51      0.53      0.52       375\n",
            "           6       0.57      0.70      0.63       424\n",
            "           7       0.57      0.53      0.55       401\n",
            "           8       0.47      0.43      0.45       349\n",
            "           9       0.63      0.61      0.62       334\n",
            "          10       0.76      0.73      0.75       437\n",
            "          11       0.49      0.62      0.55       393\n",
            "          12       0.42      0.46      0.44       404\n",
            "          13       0.83      0.71      0.77       280\n",
            "          14       0.47      0.49      0.48       483\n",
            "          15       0.43      0.47      0.45       410\n",
            "\n",
            "    accuracy                           0.75     11720\n",
            "   macro avg       0.55      0.55      0.55     11720\n",
            "weighted avg       0.75      0.75      0.75     11720\n",
            "\n",
            "\n",
            "Classifier: Logistic Regression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10969/3647427165.py:42: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.09      0.13       442\n",
            "           1       0.24      0.15      0.19       389\n",
            "           2       1.00      1.00      1.00      5790\n",
            "           3       0.28      0.10      0.15       401\n",
            "           4       0.14      0.11      0.13       408\n",
            "           5       0.20      0.29      0.24       375\n",
            "           6       0.36      0.43      0.39       424\n",
            "           7       0.28      0.27      0.28       401\n",
            "           8       0.46      0.09      0.15       349\n",
            "           9       0.36      0.13      0.19       334\n",
            "          10       0.33      0.41      0.37       437\n",
            "          11       0.29      0.26      0.28       393\n",
            "          12       0.16      0.28      0.20       404\n",
            "          13       0.57      0.52      0.54       280\n",
            "          14       0.22      0.27      0.24       483\n",
            "          15       0.17      0.39      0.23       410\n",
            "\n",
            "    accuracy                           0.62     11720\n",
            "   macro avg       0.33      0.30      0.29     11720\n",
            "weighted avg       0.63      0.62      0.62     11720\n",
            "\n",
            "\n",
            "Classifier: Support Vector...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.08      0.12       442\n",
            "           1       0.23      0.16      0.19       389\n",
            "           2       1.00      1.00      1.00      5790\n",
            "           3       0.32      0.07      0.12       401\n",
            "           4       0.24      0.16      0.19       408\n",
            "           5       0.23      0.44      0.30       375\n",
            "           6       0.39      0.42      0.40       424\n",
            "           7       0.38      0.21      0.27       401\n",
            "           8       0.34      0.11      0.16       349\n",
            "           9       0.47      0.07      0.12       334\n",
            "          10       0.63      0.34      0.44       437\n",
            "          11       0.33      0.27      0.30       393\n",
            "          12       0.17      0.30      0.21       404\n",
            "          13       0.75      0.47      0.58       280\n",
            "          14       0.20      0.33      0.24       483\n",
            "          15       0.16      0.51      0.25       410\n",
            "\n",
            "    accuracy                           0.63     11720\n",
            "   macro avg       0.38      0.31      0.31     11720\n",
            "weighted avg       0.66      0.63      0.62     11720\n",
            "\n",
            "\n",
            "Classifier: Decision Tree...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.28      0.29       442\n",
            "           1       0.30      0.31      0.31       389\n",
            "           2       1.00      1.00      1.00      5790\n",
            "           3       0.33      0.32      0.32       401\n",
            "           4       0.36      0.34      0.35       408\n",
            "           5       0.39      0.40      0.39       375\n",
            "           6       0.50      0.65      0.56       424\n",
            "           7       0.44      0.40      0.42       401\n",
            "           8       0.33      0.31      0.32       349\n",
            "           9       0.55      0.59      0.57       334\n",
            "          10       0.69      0.70      0.69       437\n",
            "          11       0.44      0.41      0.43       393\n",
            "          12       0.39      0.39      0.39       404\n",
            "          13       0.68      0.64      0.66       280\n",
            "          14       0.41      0.42      0.41       483\n",
            "          15       0.41      0.38      0.39       410\n",
            "\n",
            "    accuracy                           0.71     11720\n",
            "   macro avg       0.47      0.47      0.47     11720\n",
            "weighted avg       0.71      0.71      0.71     11720\n",
            "\n",
            "\n",
            "Classifier: Random Forest...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.36      0.40       442\n",
            "           1       0.38      0.33      0.36       389\n",
            "           2       1.00      1.00      1.00      5790\n",
            "           3       0.39      0.39      0.39       401\n",
            "           4       0.46      0.41      0.44       408\n",
            "           5       0.51      0.49      0.50       375\n",
            "           6       0.56      0.70      0.62       424\n",
            "           7       0.53      0.52      0.52       401\n",
            "           8       0.42      0.41      0.41       349\n",
            "           9       0.62      0.64      0.63       334\n",
            "          10       0.75      0.72      0.73       437\n",
            "          11       0.54      0.64      0.58       393\n",
            "          12       0.45      0.49      0.47       404\n",
            "          13       0.80      0.74      0.76       280\n",
            "          14       0.48      0.47      0.48       483\n",
            "          15       0.45      0.48      0.46       410\n",
            "\n",
            "    accuracy                           0.75     11720\n",
            "   macro avg       0.55      0.55      0.55     11720\n",
            "weighted avg       0.75      0.75      0.75     11720\n",
            "\n",
            "\n",
            "Classifier: XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [22:03:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.33      0.39       442\n",
            "           1       0.41      0.35      0.38       389\n",
            "           2       1.00      1.00      1.00      5790\n",
            "           3       0.43      0.42      0.42       401\n",
            "           4       0.47      0.42      0.45       408\n",
            "           5       0.55      0.53      0.54       375\n",
            "           6       0.55      0.75      0.64       424\n",
            "           7       0.62      0.43      0.51       401\n",
            "           8       0.46      0.37      0.41       349\n",
            "           9       0.61      0.65      0.63       334\n",
            "          10       0.71      0.75      0.73       437\n",
            "          11       0.50      0.63      0.56       393\n",
            "          12       0.45      0.50      0.48       404\n",
            "          13       0.83      0.75      0.79       280\n",
            "          14       0.50      0.51      0.51       483\n",
            "          15       0.45      0.58      0.51       410\n",
            "\n",
            "    accuracy                           0.76     11720\n",
            "   macro avg       0.56      0.56      0.56     11720\n",
            "weighted avg       0.76      0.76      0.76     11720\n",
            "\n",
            "\n",
            "Classifier: CatBoost...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.27      0.33       442\n",
            "           1       0.37      0.32      0.34       389\n",
            "           2       1.00      1.00      1.00      5790\n",
            "           3       0.41      0.36      0.38       401\n",
            "           4       0.45      0.38      0.41       408\n",
            "           5       0.48      0.47      0.48       375\n",
            "           6       0.50      0.73      0.59       424\n",
            "           7       0.61      0.39      0.47       401\n",
            "           8       0.51      0.34      0.41       349\n",
            "           9       0.58      0.65      0.61       334\n",
            "          10       0.70      0.73      0.71       437\n",
            "          11       0.44      0.58      0.50       393\n",
            "          12       0.40      0.52      0.45       404\n",
            "          13       0.78      0.71      0.75       280\n",
            "          14       0.45      0.46      0.45       483\n",
            "          15       0.43      0.53      0.48       410\n",
            "\n",
            "    accuracy                           0.74     11720\n",
            "   macro avg       0.53      0.53      0.52     11720\n",
            "weighted avg       0.74      0.74      0.74     11720\n",
            "\n",
            "\n",
            "Classifier: LightGBM...\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002769 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7659\n",
            "[LightGBM] [Info] Number of data points in the train set: 46876, number of used features: 51\n",
            "[LightGBM] [Info] Start training from score -3.404103\n",
            "[LightGBM] [Info] Start training from score -3.370651\n",
            "[LightGBM] [Info] Start training from score -0.690165\n",
            "[LightGBM] [Info] Start training from score -3.378127\n",
            "[LightGBM] [Info] Start training from score -3.390081\n",
            "[LightGBM] [Info] Start training from score -3.382515\n",
            "[LightGBM] [Info] Start training from score -3.273142\n",
            "[LightGBM] [Info] Start training from score -3.404745\n",
            "[LightGBM] [Info] Start training from score -3.534156\n",
            "[LightGBM] [Info] Start training from score -3.635625\n",
            "[LightGBM] [Info] Start training from score -3.400899\n",
            "[LightGBM] [Info] Start training from score -3.373137\n",
            "[LightGBM] [Info] Start training from score -3.302859\n",
            "[LightGBM] [Info] Start training from score -3.725288\n",
            "[LightGBM] [Info] Start training from score -3.191541\n",
            "[LightGBM] [Info] Start training from score -3.415723\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.34      0.40       442\n",
            "           1       0.43      0.34      0.38       389\n",
            "           2       1.00      1.00      1.00      5790\n",
            "           3       0.45      0.42      0.43       401\n",
            "           4       0.47      0.42      0.45       408\n",
            "           5       0.55      0.52      0.53       375\n",
            "           6       0.53      0.76      0.63       424\n",
            "           7       0.58      0.42      0.49       401\n",
            "           8       0.51      0.38      0.43       349\n",
            "           9       0.65      0.66      0.65       334\n",
            "          10       0.75      0.75      0.75       437\n",
            "          11       0.52      0.65      0.58       393\n",
            "          12       0.45      0.53      0.49       404\n",
            "          13       0.85      0.77      0.81       280\n",
            "          14       0.47      0.52      0.49       483\n",
            "          15       0.45      0.58      0.51       410\n",
            "\n",
            "    accuracy                           0.76     11720\n",
            "   macro avg       0.57      0.57      0.56     11720\n",
            "weighted avg       0.77      0.76      0.76     11720\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "      <th>Recall Score</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adaboost</td>\n",
              "      <td>0.753498</td>\n",
              "      <td>0.752882</td>\n",
              "      <td>0.754248</td>\n",
              "      <td>0.753498</td>\n",
              "      <td>50.8641</td>\n",
              "      <td>0.1136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.621331</td>\n",
              "      <td>0.616804</td>\n",
              "      <td>0.634943</td>\n",
              "      <td>0.621331</td>\n",
              "      <td>7.7608</td>\n",
              "      <td>0.0015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Support Vector</td>\n",
              "      <td>0.626792</td>\n",
              "      <td>0.623525</td>\n",
              "      <td>0.659150</td>\n",
              "      <td>0.626792</td>\n",
              "      <td>31.9047</td>\n",
              "      <td>7.2170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.712201</td>\n",
              "      <td>0.710906</td>\n",
              "      <td>0.710688</td>\n",
              "      <td>0.712201</td>\n",
              "      <td>0.6190</td>\n",
              "      <td>0.0016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.754437</td>\n",
              "      <td>0.753200</td>\n",
              "      <td>0.753577</td>\n",
              "      <td>0.754437</td>\n",
              "      <td>7.5146</td>\n",
              "      <td>0.1257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.761263</td>\n",
              "      <td>0.758788</td>\n",
              "      <td>0.761376</td>\n",
              "      <td>0.761263</td>\n",
              "      <td>3.1141</td>\n",
              "      <td>0.0357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.743003</td>\n",
              "      <td>0.739763</td>\n",
              "      <td>0.744476</td>\n",
              "      <td>0.743003</td>\n",
              "      <td>66.4980</td>\n",
              "      <td>0.1219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.764078</td>\n",
              "      <td>0.761597</td>\n",
              "      <td>0.765066</td>\n",
              "      <td>0.764078</td>\n",
              "      <td>3.0143</td>\n",
              "      <td>0.1498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Model Name  Accuracy Score  F1 Score  Precision Score  \\\n",
              "0             Adaboost        0.753498  0.752882         0.754248   \n",
              "1  Logistic Regression        0.621331  0.616804         0.634943   \n",
              "2       Support Vector        0.626792  0.623525         0.659150   \n",
              "3        Decision Tree        0.712201  0.710906         0.710688   \n",
              "4        Random Forest        0.754437  0.753200         0.753577   \n",
              "5              XGBoost        0.761263  0.758788         0.761376   \n",
              "6             CatBoost        0.743003  0.739763         0.744476   \n",
              "7             LightGBM        0.764078  0.761597         0.765066   \n",
              "\n",
              "   Recall Score  Training Time (s)  Inference Time (s)  \n",
              "0      0.753498            50.8641              0.1136  \n",
              "1      0.621331             7.7608              0.0015  \n",
              "2      0.626792            31.9047              7.2170  \n",
              "3      0.712201             0.6190              0.0016  \n",
              "4      0.754437             7.5146              0.1257  \n",
              "5      0.761263             3.1141              0.0357  \n",
              "6      0.743003            66.4980              0.1219  \n",
              "7      0.764078             3.0143              0.1498  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "import time\n",
        "\n",
        "# Add columns for training and inference time\n",
        "metrics_sbtsk3 = pd.DataFrame(columns=[\n",
        "    \"Model Name\", \"Accuracy Score\", \"F1 Score\", \"Precision Score\", \"Recall Score\",\n",
        "    \"Training Time (s)\", \"Inference Time (s)\"\n",
        "])\n",
        "\n",
        "for classifier_name, classifier in classifiers:\n",
        "    print(f\"\\nClassifier: {classifier_name}...\")\n",
        "\n",
        "    # Time the training\n",
        "    start_train = time.time()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    end_train = time.time()\n",
        "    training_time = end_train - start_train\n",
        "\n",
        "    # Time the inference\n",
        "    start_infer = time.time()\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    end_infer = time.time()\n",
        "    inference_time = end_infer - start_infer\n",
        "\n",
        "    # Print classification report\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Collect metrics with timing\n",
        "    new_metrics = pd.DataFrame([{\n",
        "        \"Model Name\": classifier_name,\n",
        "        \"Accuracy Score\": accuracy_score(y_test, y_pred),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred, average='weighted'),\n",
        "        \"Precision Score\": precision_score(y_test, y_pred, average='weighted'),\n",
        "        \"Recall Score\": recall_score(y_test, y_pred, average='weighted'),\n",
        "        \"Training Time (s)\": round(training_time, 4),\n",
        "        \"Inference Time (s)\": round(inference_time, 4)\n",
        "    }])\n",
        "\n",
        "    # Append to the metrics table\n",
        "    metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n",
        "\n",
        "# Show final results\n",
        "metrics_sbtsk3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8LwBWElS2av3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC Score: 0.9780842722458016\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Binarize labels for multiclass\n",
        "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))  \n",
        "y_prob = classifier.predict_proba(X_test)\n",
        "\n",
        "auc_score = roc_auc_score(y_test_bin, y_prob, average='weighted', multi_class='ovr')\n",
        "print(\"ROC AUC Score:\", auc_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgHLYt1F7c0m"
      },
      "source": [
        "**Ensemble**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0yfJ4oDUdrqy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4248\n",
            "[LightGBM] [Info] Number of data points in the train set: 1519, number of used features: 47\n",
            "[LightGBM] [Info] Start training from score -2.435458\n",
            "[LightGBM] [Info] Start training from score -2.546684\n",
            "[LightGBM] [Info] Start training from score -2.563634\n",
            "[LightGBM] [Info] Start training from score -2.427968\n",
            "[LightGBM] [Info] Start training from score -2.804019\n",
            "[LightGBM] [Info] Start training from score -2.919088\n",
            "[LightGBM] [Info] Start training from score -2.837171\n",
            "[LightGBM] [Info] Start training from score -2.804019\n",
            "[LightGBM] [Info] Start training from score -3.021742\n",
            "[LightGBM] [Info] Start training from score -3.091701\n",
            "[LightGBM] [Info] Start training from score -2.793208\n",
            "[LightGBM] [Info] Start training from score -2.450610\n",
            "[LightGBM] [Info] Start training from score -3.413784\n",
            "[LightGBM] [Info] Start training from score -2.616277\n",
            "[LightGBM] [Info] Start training from score -2.435458\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10969/3724069315.py:70: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "      <th>Recall Score</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoost-LightGBM</td>\n",
              "      <td>0.848549</td>\n",
              "      <td>0.848209</td>\n",
              "      <td>0.849661</td>\n",
              "      <td>0.848549</td>\n",
              "      <td>53.2835</td>\n",
              "      <td>0.1502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Model Name  Accuracy Score  F1 Score  Precision Score  Recall Score  \\\n",
              "0  AdaBoost-LightGBM        0.848549  0.848209         0.849661      0.848549   \n",
              "\n",
              "   Training Time (s)  Inference Time (s)  \n",
              "0            53.2835              0.1502  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Timing and performance DataFrame\n",
        "metrics_sbtsk3 = pd.DataFrame(columns=[\n",
        "    \"Model Name\", \"Accuracy Score\", \"F1 Score\", \"Precision Score\", \"Recall Score\",\n",
        "    \"Training Time (s)\", \"Inference Time (s)\"\n",
        "])\n",
        "\n",
        "# Step 1: Train AdaBoost\n",
        "start_train = time.time()\n",
        "adaboost = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=20), n_estimators=50, random_state=42)\n",
        "adaboost.fit(X_train, y_train)\n",
        "train_time_ada = time.time() - start_train\n",
        "\n",
        "# Inference (predict_proba)\n",
        "start_infer = time.time()\n",
        "adaboost_proba = adaboost.predict_proba(X_test)\n",
        "infer_time_ada = time.time() - start_infer\n",
        "\n",
        "adaboost_pred = np.argmax(adaboost_proba, axis=1)\n",
        "\n",
        "# Confidence threshold\n",
        "confidence_threshold = 0.8\n",
        "max_probs = np.max(adaboost_proba, axis=1)\n",
        "uncertain_indices = np.where(max_probs < confidence_threshold)[0]\n",
        "certain_indices = np.where(max_probs >= confidence_threshold)[0]\n",
        "\n",
        "# Step 2: Train LightGBM on uncertain predictions\n",
        "start_train_lgbm = time.time()\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_test[uncertain_indices], y_test.iloc[uncertain_indices])\n",
        "train_time_lgbm = time.time() - start_train_lgbm\n",
        "\n",
        "# Inference on uncertain predictions\n",
        "start_infer_lgbm = time.time()\n",
        "lgbm_preds = lgbm.predict(X_test[uncertain_indices])\n",
        "infer_time_lgbm = time.time() - start_infer_lgbm\n",
        "\n",
        "# Step 3: Combine predictions\n",
        "final_predictions = adaboost_pred.copy()\n",
        "final_predictions[uncertain_indices] = lgbm_preds\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "f1 = f1_score(y_test, final_predictions, average='weighted')\n",
        "precision = precision_score(y_test, final_predictions, average='weighted')\n",
        "recall = recall_score(y_test, final_predictions, average='weighted')\n",
        "\n",
        "# Total timing\n",
        "total_train_time = train_time_ada + train_time_lgbm\n",
        "total_infer_time = infer_time_ada + infer_time_lgbm\n",
        "\n",
        "# Store results\n",
        "new_metrics = pd.DataFrame([{\n",
        "    \"Model Name\": \"AdaBoost-LightGBM\",\n",
        "    \"Accuracy Score\": accuracy,\n",
        "    \"F1 Score\": f1,\n",
        "    \"Precision Score\": precision,\n",
        "    \"Recall Score\": recall,\n",
        "    \"Training Time (s)\": round(total_train_time, 4),\n",
        "    \"Inference Time (s)\": round(total_infer_time, 4)\n",
        "}])\n",
        "\n",
        "metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n",
        "\n",
        "# Show results\n",
        "metrics_sbtsk3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5DBsX7CXZNyR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5432\n",
            "[LightGBM] [Info] Number of data points in the train set: 5698, number of used features: 47\n",
            "[LightGBM] [Info] Start training from score -2.570228\n",
            "[LightGBM] [Info] Start training from score -2.689446\n",
            "[LightGBM] [Info] Start training from score -7.549258\n",
            "[LightGBM] [Info] Start training from score -2.676609\n",
            "[LightGBM] [Info] Start training from score -2.651418\n",
            "[LightGBM] [Info] Start training from score -2.723615\n",
            "[LightGBM] [Info] Start training from score -2.598137\n",
            "[LightGBM] [Info] Start training from score -2.663934\n",
            "[LightGBM] [Info] Start training from score -2.810140\n",
            "[LightGBM] [Info] Start training from score -2.864045\n",
            "[LightGBM] [Info] Start training from score -2.739788\n",
            "[LightGBM] [Info] Start training from score -2.674061\n",
            "[LightGBM] [Info] Start training from score -2.648934\n",
            "[LightGBM] [Info] Start training from score -3.411429\n",
            "[LightGBM] [Info] Start training from score -2.472003\n",
            "[LightGBM] [Info] Start training from score -2.702450\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10969/95593994.py:69: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "      <th>Recall Score</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression-LightGBM</td>\n",
              "      <td>0.986348</td>\n",
              "      <td>0.986359</td>\n",
              "      <td>0.986585</td>\n",
              "      <td>0.986348</td>\n",
              "      <td>8.9681</td>\n",
              "      <td>0.108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Model Name  Accuracy Score  F1 Score  Precision Score  \\\n",
              "0  Logistic Regression-LightGBM        0.986348  0.986359         0.986585   \n",
              "\n",
              "   Recall Score  Training Time (s)  Inference Time (s)  \n",
              "0      0.986348             8.9681               0.108  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Initialize DataFrame for metrics including timing\n",
        "metrics_sbtsk3 = pd.DataFrame(columns=[\n",
        "    \"Model Name\", \"Accuracy Score\", \"F1 Score\", \"Precision Score\", \"Recall Score\",\n",
        "    \"Training Time (s)\", \"Inference Time (s)\"\n",
        "])\n",
        "\n",
        "# Step 1: Train Logistic Regression\n",
        "start_train_logreg = time.time()\n",
        "logreg = LogisticRegression(penalty=\"l2\", C=10, max_iter=10000, random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "train_time_logreg = time.time() - start_train_logreg\n",
        "\n",
        "# Logistic Regression inference (predict_proba)\n",
        "start_infer_logreg = time.time()\n",
        "logreg_proba = logreg.predict_proba(X_test)\n",
        "infer_time_logreg = time.time() - start_infer_logreg\n",
        "\n",
        "logreg_pred = np.argmax(logreg_proba, axis=1)\n",
        "\n",
        "# Confidence threshold\n",
        "confidence_threshold = 0.8\n",
        "max_probs = np.max(logreg_proba, axis=1)\n",
        "uncertain_indices = np.where(max_probs < confidence_threshold)[0]\n",
        "certain_indices = np.where(max_probs >= confidence_threshold)[0]\n",
        "\n",
        "# Step 2: Train LightGBM on uncertain predictions\n",
        "start_train_lgbm = time.time()\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_test[uncertain_indices], y_test.iloc[uncertain_indices])\n",
        "train_time_lgbm = time.time() - start_train_lgbm\n",
        "\n",
        "# LightGBM inference on uncertain predictions\n",
        "start_infer_lgbm = time.time()\n",
        "lgbm_preds = lgbm.predict(X_test[uncertain_indices])\n",
        "infer_time_lgbm = time.time() - start_infer_lgbm\n",
        "\n",
        "# Step 3: Combine predictions\n",
        "final_predictions = logreg_pred.copy()\n",
        "final_predictions[uncertain_indices] = lgbm_preds\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "f1 = f1_score(y_test, final_predictions, average='weighted')\n",
        "precision = precision_score(y_test, final_predictions, average='weighted')\n",
        "recall = recall_score(y_test, final_predictions, average='weighted')\n",
        "\n",
        "# Sum total training and inference times\n",
        "total_train_time = train_time_logreg + train_time_lgbm\n",
        "total_infer_time = infer_time_logreg + infer_time_lgbm\n",
        "\n",
        "# Append results to metrics DataFrame\n",
        "new_metrics = pd.DataFrame([{\n",
        "    \"Model Name\": \"Logistic Regression-LightGBM\",\n",
        "    \"Accuracy Score\": accuracy,\n",
        "    \"F1 Score\": f1,\n",
        "    \"Precision Score\": precision,\n",
        "    \"Recall Score\": recall,\n",
        "    \"Training Time (s)\": round(total_train_time, 4),\n",
        "    \"Inference Time (s)\": round(total_infer_time, 4)\n",
        "}])\n",
        "\n",
        "metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n",
        "\n",
        "# Display results\n",
        "metrics_sbtsk3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "udqd6iHLk1i4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5598\n",
            "[LightGBM] [Info] Number of data points in the train set: 5896, number of used features: 47\n",
            "[LightGBM] [Info] Start training from score -2.590720\n",
            "[LightGBM] [Info] Start training from score -2.718450\n",
            "[LightGBM] [Info] Start training from score -7.583417\n",
            "[LightGBM] [Info] Start training from score -2.688068\n",
            "[LightGBM] [Info] Start training from score -2.675676\n",
            "[LightGBM] [Info] Start training from score -2.755103\n",
            "[LightGBM] [Info] Start training from score -2.637024\n",
            "[LightGBM] [Info] Start training from score -2.693068\n",
            "[LightGBM] [Info] Start training from score -2.832705\n",
            "[LightGBM] [Info] Start training from score -2.870888\n",
            "[LightGBM] [Info] Start training from score -2.602096\n",
            "[LightGBM] [Info] Start training from score -2.708220\n",
            "[LightGBM] [Info] Start training from score -2.680615\n",
            "[LightGBM] [Info] Start training from score -3.098533\n",
            "[LightGBM] [Info] Start training from score -2.504085\n",
            "[LightGBM] [Info] Start training from score -2.700615\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10969/1989598382.py:69: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "      <th>Recall Score</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Support Vector-LightGBM</td>\n",
              "      <td>0.988225</td>\n",
              "      <td>0.988227</td>\n",
              "      <td>0.988401</td>\n",
              "      <td>0.988225</td>\n",
              "      <td>158.466</td>\n",
              "      <td>7.573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model Name  Accuracy Score  F1 Score  Precision Score  \\\n",
              "0  Support Vector-LightGBM        0.988225  0.988227         0.988401   \n",
              "\n",
              "   Recall Score  Training Time (s)  Inference Time (s)  \n",
              "0      0.988225            158.466               7.573  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.svm import SVC\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Initialize metrics DataFrame with timing columns\n",
        "metrics_sbtsk3 = pd.DataFrame(columns=[\n",
        "    \"Model Name\", \"Accuracy Score\", \"F1 Score\", \"Precision Score\", \"Recall Score\",\n",
        "    \"Training Time (s)\", \"Inference Time (s)\"\n",
        "])\n",
        "\n",
        "# Step 1: Train SVC\n",
        "start_train_svc = time.time()\n",
        "svc = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
        "svc.fit(X_train, y_train)\n",
        "train_time_svc = time.time() - start_train_svc\n",
        "\n",
        "# SVC inference (predict_proba)\n",
        "start_infer_svc = time.time()\n",
        "svc_proba = svc.predict_proba(X_test)\n",
        "infer_time_svc = time.time() - start_infer_svc\n",
        "\n",
        "svc_pred = np.argmax(svc_proba, axis=1)\n",
        "\n",
        "# Confidence threshold and low-confidence indices\n",
        "confidence_threshold = 0.8\n",
        "max_probs = np.max(svc_proba, axis=1)\n",
        "uncertain_indices = np.where(max_probs < confidence_threshold)[0]\n",
        "certain_indices = np.where(max_probs >= confidence_threshold)[0]\n",
        "\n",
        "# Step 2: Train LightGBM on uncertain cases\n",
        "start_train_lgbm = time.time()\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_test[uncertain_indices], y_test.iloc[uncertain_indices])\n",
        "train_time_lgbm = time.time() - start_train_lgbm\n",
        "\n",
        "# LightGBM inference on uncertain cases\n",
        "start_infer_lgbm = time.time()\n",
        "lgbm_preds = lgbm.predict(X_test[uncertain_indices])\n",
        "infer_time_lgbm = time.time() - start_infer_lgbm\n",
        "\n",
        "# Step 3: Combine predictions\n",
        "final_predictions = svc_pred.copy()\n",
        "final_predictions[uncertain_indices] = lgbm_preds\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "f1 = f1_score(y_test, final_predictions, average='weighted')\n",
        "precision = precision_score(y_test, final_predictions, average='weighted')\n",
        "recall = recall_score(y_test, final_predictions, average='weighted')\n",
        "\n",
        "# Sum training and inference times\n",
        "total_train_time = train_time_svc + train_time_lgbm\n",
        "total_infer_time = infer_time_svc + infer_time_lgbm\n",
        "\n",
        "# Append results\n",
        "new_metrics = pd.DataFrame([{\n",
        "    \"Model Name\": \"Support Vector-LightGBM\",\n",
        "    \"Accuracy Score\": accuracy,\n",
        "    \"F1 Score\": f1,\n",
        "    \"Precision Score\": precision,\n",
        "    \"Recall Score\": recall,\n",
        "    \"Training Time (s)\": round(total_train_time, 4),\n",
        "    \"Inference Time (s)\": round(total_infer_time, 4)\n",
        "}])\n",
        "\n",
        "metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n",
        "\n",
        "# Show results\n",
        "metrics_sbtsk3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nGW2Hg2uk1l4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/azwad/anaconda3/envs/Final/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5291\n",
            "[LightGBM] [Info] Number of data points in the train set: 5481, number of used features: 47\n",
            "[LightGBM] [Info] Start training from score -2.524543\n",
            "[LightGBM] [Info] Start training from score -2.682117\n",
            "[LightGBM] [Info] Start training from score -7.510431\n",
            "[LightGBM] [Info] Start training from score -2.645464\n",
            "[LightGBM] [Info] Start training from score -2.597776\n",
            "[LightGBM] [Info] Start training from score -2.751110\n",
            "[LightGBM] [Info] Start training from score -2.564038\n",
            "[LightGBM] [Info] Start training from score -2.642896\n",
            "[LightGBM] [Info] Start training from score -2.825218\n",
            "[LightGBM] [Info] Start training from score -2.803908\n",
            "[LightGBM] [Info] Start training from score -2.918683\n",
            "[LightGBM] [Info] Start training from score -2.648038\n",
            "[LightGBM] [Info] Start training from score -2.671507\n",
            "[LightGBM] [Info] Start training from score -3.578605\n",
            "[LightGBM] [Info] Start training from score -2.479993\n",
            "[LightGBM] [Info] Start training from score -2.687464\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "      <th>Recall Score</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Decision Tree-LightGBM</td>\n",
              "      <td>0.623038</td>\n",
              "      <td>0.622822</td>\n",
              "      <td>0.639612</td>\n",
              "      <td>0.623038</td>\n",
              "      <td>1.4214</td>\n",
              "      <td>0.0908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model Name  Accuracy Score  F1 Score  Precision Score  \\\n",
              "0  Decision Tree-LightGBM        0.623038  0.622822         0.639612   \n",
              "\n",
              "   Recall Score  Training Time (s)  Inference Time (s)  \n",
              "0      0.623038             1.4214              0.0908  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Convert X_test and y_test to DataFrame/Series if needed\n",
        "X_test_df = pd.DataFrame(X_test, columns=X.columns) if isinstance(X_test, np.ndarray) else X_test\n",
        "y_test_df = pd.Series(y_test) if isinstance(y_test, np.ndarray) else y_test\n",
        "\n",
        "# Step 1: Train Decision Tree\n",
        "start_train_dt = time.time()\n",
        "dt = DecisionTreeClassifier(random_state=42, min_samples_leaf=10, min_samples_split=5, max_depth=10, criterion='entropy')\n",
        "dt.fit(X_train, y_train)\n",
        "train_time_dt = time.time() - start_train_dt\n",
        "\n",
        "# Predict with DT (inference)\n",
        "start_infer_dt = time.time()\n",
        "dt_proba = dt.predict_proba(X_test_df)\n",
        "infer_time_dt = time.time() - start_infer_dt\n",
        "\n",
        "dt_pred = np.argmax(dt_proba, axis=1)\n",
        "\n",
        "# Confidence threshold and uncertain cases\n",
        "confidence_threshold = 0.8\n",
        "max_probs = np.max(dt_proba, axis=1)\n",
        "uncertain_indices = np.where(max_probs < confidence_threshold)[0]\n",
        "certain_indices = np.where(max_probs >= confidence_threshold)[0]\n",
        "\n",
        "# Step 2: Train LightGBM on uncertain samples\n",
        "start_train_lgbm = time.time()\n",
        "lgbm = LGBMClassifier()\n",
        "lgbm.fit(X_test_df.iloc[uncertain_indices], y_test_df.iloc[uncertain_indices])\n",
        "train_time_lgbm = time.time() - start_train_lgbm\n",
        "\n",
        "# LightGBM inference on uncertain samples\n",
        "start_infer_lgbm = time.time()\n",
        "lgbm_preds = lgbm.predict(X_test_df.iloc[uncertain_indices])\n",
        "infer_time_lgbm = time.time() - start_infer_lgbm\n",
        "\n",
        "# Combine predictions\n",
        "final_predictions = dt_pred.copy()\n",
        "final_predictions[uncertain_indices] = lgbm_preds\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "f1 = f1_score(y_test, final_predictions, average='weighted')\n",
        "precision = precision_score(y_test, final_predictions, average='weighted')\n",
        "recall = recall_score(y_test, final_predictions, average='weighted')\n",
        "\n",
        "# Total training and inference time\n",
        "total_train_time = train_time_dt + train_time_lgbm\n",
        "total_infer_time = infer_time_dt + infer_time_lgbm\n",
        "\n",
        "# Store metrics and timing in DataFrame\n",
        "metrics_sbtsk3 = pd.DataFrame([{\n",
        "    \"Model Name\": \"Decision Tree-LightGBM\",\n",
        "    \"Accuracy Score\": accuracy,\n",
        "    \"F1 Score\": f1,\n",
        "    \"Precision Score\": precision,\n",
        "    \"Recall Score\": recall,\n",
        "    \"Training Time (s)\": round(total_train_time, 4),\n",
        "    \"Inference Time (s)\": round(total_infer_time, 4)\n",
        "}])\n",
        "\n",
        "metrics_sbtsk3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fsaOVXbbk1ra"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5342\n",
            "[LightGBM] [Info] Number of data points in the train set: 4995, number of used features: 47\n",
            "[LightGBM] [Info] Start training from score -2.524728\n",
            "[LightGBM] [Info] Start training from score -2.581298\n",
            "[LightGBM] [Info] Start training from score -6.570283\n",
            "[LightGBM] [Info] Start training from score -2.573393\n",
            "[LightGBM] [Info] Start training from score -2.562949\n",
            "[LightGBM] [Info] Start training from score -2.799165\n",
            "[LightGBM] [Info] Start training from score -2.711058\n",
            "[LightGBM] [Info] Start training from score -2.766800\n",
            "[LightGBM] [Info] Start training from score -2.766800\n",
            "[LightGBM] [Info] Start training from score -3.039729\n",
            "[LightGBM] [Info] Start training from score -2.959365\n",
            "[LightGBM] [Info] Start training from score -2.649725\n",
            "[LightGBM] [Info] Start training from score -2.621790\n",
            "[LightGBM] [Info] Start training from score -3.472768\n",
            "[LightGBM] [Info] Start training from score -2.415874\n",
            "[LightGBM] [Info] Start training from score -2.616295\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10969/1164823959.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "      <th>Recall Score</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest-LightGBM</td>\n",
              "      <td>0.985239</td>\n",
              "      <td>0.985267</td>\n",
              "      <td>0.985483</td>\n",
              "      <td>0.985239</td>\n",
              "      <td>8.564</td>\n",
              "      <td>0.2262</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model Name  Accuracy Score  F1 Score  Precision Score  \\\n",
              "0  Random Forest-LightGBM        0.985239  0.985267         0.985483   \n",
              "\n",
              "   Recall Score  Training Time (s)  Inference Time (s)  \n",
              "0      0.985239              8.564              0.2262  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Step 1: Train Random Forest (Timing)\n",
        "start_train_rf = time.time()\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "train_time_rf = time.time() - start_train_rf\n",
        "\n",
        "# Inference with Random Forest\n",
        "start_infer_rf = time.time()\n",
        "rf_proba = rf.predict_proba(X_test)\n",
        "rf_pred = np.argmax(rf_proba, axis=1)\n",
        "infer_time_rf = time.time() - start_infer_rf\n",
        "\n",
        "# Set confidence threshold\n",
        "confidence_threshold = 0.8\n",
        "max_probs = np.max(rf_proba, axis=1)\n",
        "uncertain_indices = np.where(max_probs < confidence_threshold)[0]\n",
        "\n",
        "# Step 2: Train LightGBM on uncertain cases (Timing)\n",
        "start_train_lgbm = time.time()\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_test[uncertain_indices], y_test.iloc[uncertain_indices])\n",
        "train_time_lgbm = time.time() - start_train_lgbm\n",
        "\n",
        "# Inference with LightGBM\n",
        "start_infer_lgbm = time.time()\n",
        "final_predictions = rf_pred.copy()\n",
        "final_predictions[uncertain_indices] = lgbm.predict(X_test[uncertain_indices])\n",
        "infer_time_lgbm = time.time() - start_infer_lgbm\n",
        "\n",
        "# Step 3: Evaluate and store results\n",
        "metrics_sbtsk3 = pd.DataFrame(columns=[\n",
        "    \"Model Name\", \"Accuracy Score\", \"F1 Score\", \"Precision Score\", \"Recall Score\",\n",
        "    \"Training Time (s)\", \"Inference Time (s)\"\n",
        "])\n",
        "\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "f1 = f1_score(y_test, final_predictions, average='weighted')\n",
        "precision = precision_score(y_test, final_predictions, average='weighted')\n",
        "recall = recall_score(y_test, final_predictions, average='weighted')\n",
        "\n",
        "# Add result row\n",
        "new_metrics = pd.DataFrame([{\n",
        "    \"Model Name\": \"Random Forest-LightGBM\",\n",
        "    \"Accuracy Score\": accuracy,\n",
        "    \"F1 Score\": f1,\n",
        "    \"Precision Score\": precision,\n",
        "    \"Recall Score\": recall,\n",
        "    \"Training Time (s)\": round(train_time_rf + train_time_lgbm, 4),\n",
        "    \"Inference Time (s)\": round(infer_time_rf + infer_time_lgbm, 4)\n",
        "}])\n",
        "\n",
        "metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n",
        "\n",
        "# Display results\n",
        "metrics_sbtsk3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XPsnSi4-k1vJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5280\n",
            "[LightGBM] [Info] Number of data points in the train set: 5245, number of used features: 47\n",
            "[LightGBM] [Info] Start training from score -2.527160\n",
            "[LightGBM] [Info] Start training from score -2.614388\n",
            "[LightGBM] [Info] Start training from score -2.604025\n",
            "[LightGBM] [Info] Start training from score -2.609193\n",
            "[LightGBM] [Info] Start training from score -2.772017\n",
            "[LightGBM] [Info] Start training from score -2.541583\n",
            "[LightGBM] [Info] Start training from score -2.704244\n",
            "[LightGBM] [Info] Start training from score -2.781205\n",
            "[LightGBM] [Info] Start training from score -2.992876\n",
            "[LightGBM] [Info] Start training from score -2.881451\n",
            "[LightGBM] [Info] Start training from score -2.659669\n",
            "[LightGBM] [Info] Start training from score -2.673386\n",
            "[LightGBM] [Info] Start training from score -3.630557\n",
            "[LightGBM] [Info] Start training from score -2.427303\n",
            "[LightGBM] [Info] Start training from score -2.670628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10969/1735620659.py:69: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "      <th>Recall Score</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBoost-LightGBM</td>\n",
              "      <td>0.988225</td>\n",
              "      <td>0.988238</td>\n",
              "      <td>0.988465</td>\n",
              "      <td>0.988225</td>\n",
              "      <td>3.8073</td>\n",
              "      <td>0.1356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Model Name  Accuracy Score  F1 Score  Precision Score  Recall Score  \\\n",
              "0  XGBoost-LightGBM        0.988225  0.988238         0.988465      0.988225   \n",
              "\n",
              "   Training Time (s)  Inference Time (s)  \n",
              "0             3.8073              0.1356  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Convert X_test and y_test to DataFrame/Series if needed\n",
        "X_test_df = pd.DataFrame(X_test, columns=X.columns) if isinstance(X_test, np.ndarray) else X_test\n",
        "y_test_df = pd.Series(y_test) if isinstance(y_test, np.ndarray) else y_test\n",
        "\n",
        "# Step 1: Train XGBoost\n",
        "start_train_xgb = time.time()\n",
        "xgb = XGBClassifier(eval_metric=\"mlogloss\", objective=\"multi:softmax\", num_class=len(y.unique()), random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "train_time_xgb = time.time() - start_train_xgb\n",
        "\n",
        "# XGBoost inference\n",
        "start_infer_xgb = time.time()\n",
        "xgb_proba = xgb.predict_proba(X_test_df)\n",
        "infer_time_xgb = time.time() - start_infer_xgb\n",
        "\n",
        "xgb_pred = np.argmax(xgb_proba, axis=1)\n",
        "\n",
        "# Threshold for low-confidence samples\n",
        "confidence_threshold = 0.9\n",
        "max_probs = np.max(xgb_proba, axis=1)\n",
        "uncertain_indices = np.where(max_probs < confidence_threshold)[0]\n",
        "certain_indices = np.where(max_probs >= confidence_threshold)[0]\n",
        "\n",
        "# Step 2: Train LightGBM on uncertain samples\n",
        "start_train_lgbm = time.time()\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_test_df.iloc[uncertain_indices], y_test_df.iloc[uncertain_indices])\n",
        "train_time_lgbm = time.time() - start_train_lgbm\n",
        "\n",
        "# LightGBM inference on uncertain samples\n",
        "start_infer_lgbm = time.time()\n",
        "lgbm_preds = lgbm.predict(X_test_df.iloc[uncertain_indices])\n",
        "infer_time_lgbm = time.time() - start_infer_lgbm\n",
        "\n",
        "# Combine predictions\n",
        "final_predictions = xgb_pred.copy()\n",
        "final_predictions[uncertain_indices] = lgbm_preds\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "f1 = f1_score(y_test, final_predictions, average='weighted')\n",
        "precision = precision_score(y_test, final_predictions, average='weighted')\n",
        "recall = recall_score(y_test, final_predictions, average='weighted')\n",
        "\n",
        "# Total training and inference time\n",
        "total_train_time = train_time_xgb + train_time_lgbm\n",
        "total_infer_time = infer_time_xgb + infer_time_lgbm\n",
        "\n",
        "# Initialize or append to metrics DataFrame\n",
        "metrics_sbtsk3 = pd.DataFrame(columns=[\"Model Name\", \"Accuracy Score\", \"F1 Score\", \"Precision Score\", \"Recall Score\", \"Training Time (s)\", \"Inference Time (s)\"])\n",
        "\n",
        "new_metrics = pd.DataFrame([{\n",
        "    \"Model Name\": \"XGBoost-LightGBM\",\n",
        "    \"Accuracy Score\": accuracy,\n",
        "    \"F1 Score\": f1,\n",
        "    \"Precision Score\": precision,\n",
        "    \"Recall Score\": recall,\n",
        "    \"Training Time (s)\": round(total_train_time, 4),\n",
        "    \"Inference Time (s)\": round(total_infer_time, 4)\n",
        "}])\n",
        "\n",
        "metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n",
        "\n",
        "metrics_sbtsk3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GD3VIShywf6O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5301\n",
            "[LightGBM] [Info] Number of data points in the train set: 5369, number of used features: 47\n",
            "[LightGBM] [Info] Start training from score -2.543392\n",
            "[LightGBM] [Info] Start training from score -2.632560\n",
            "[LightGBM] [Info] Start training from score -2.619689\n",
            "[LightGBM] [Info] Start training from score -2.614587\n",
            "[LightGBM] [Info] Start training from score -2.739072\n",
            "[LightGBM] [Info] Start training from score -2.555311\n",
            "[LightGBM] [Info] Start training from score -2.707864\n",
            "[LightGBM] [Info] Start training from score -2.820076\n",
            "[LightGBM] [Info] Start training from score -2.911643\n",
            "[LightGBM] [Info] Start training from score -2.884614\n",
            "[LightGBM] [Info] Start training from score -2.642976\n",
            "[LightGBM] [Info] Start training from score -2.658808\n",
            "[LightGBM] [Info] Start training from score -3.611663\n",
            "[LightGBM] [Info] Start training from score -2.446360\n",
            "[LightGBM] [Info] Start training from score -2.661471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10969/1793199631.py:69: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Precision Score</th>\n",
              "      <th>Recall Score</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CatBoost-LightGBM</td>\n",
              "      <td>0.988652</td>\n",
              "      <td>0.988672</td>\n",
              "      <td>0.98889</td>\n",
              "      <td>0.988652</td>\n",
              "      <td>67.8026</td>\n",
              "      <td>0.112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Model Name  Accuracy Score  F1 Score  Precision Score  Recall Score  \\\n",
              "0  CatBoost-LightGBM        0.988652  0.988672          0.98889      0.988652   \n",
              "\n",
              "   Training Time (s)  Inference Time (s)  \n",
              "0            67.8026               0.112  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Convert X_test and y_test to DataFrame/Series if needed for safe indexing\n",
        "X_test_df = pd.DataFrame(X_test, columns=X.columns) if isinstance(X_test, np.ndarray) else X_test\n",
        "y_test_df = pd.Series(y_test) if isinstance(y_test, np.ndarray) else y_test\n",
        "\n",
        "# Step 1: Train CatBoost\n",
        "start_train_cat = time.time()\n",
        "catboost = CatBoostClassifier(verbose=0, random_state=42)\n",
        "catboost.fit(X_train, y_train)\n",
        "train_time_cat = time.time() - start_train_cat\n",
        "\n",
        "# CatBoost inference\n",
        "start_infer_cat = time.time()\n",
        "catboost_proba = catboost.predict_proba(X_test_df)\n",
        "infer_time_cat = time.time() - start_infer_cat\n",
        "\n",
        "catboost_pred = np.argmax(catboost_proba, axis=1)\n",
        "\n",
        "# Set confidence threshold\n",
        "confidence_threshold = 0.8\n",
        "max_probs = np.max(catboost_proba, axis=1)\n",
        "uncertain_indices = np.where(max_probs < confidence_threshold)[0]\n",
        "certain_indices = np.where(max_probs >= confidence_threshold)[0]\n",
        "\n",
        "# Step 2: Train LightGBM on uncertain cases\n",
        "start_train_lgbm = time.time()\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_test_df.iloc[uncertain_indices], y_test_df.iloc[uncertain_indices])\n",
        "train_time_lgbm = time.time() - start_train_lgbm\n",
        "\n",
        "# LightGBM inference on uncertain samples\n",
        "start_infer_lgbm = time.time()\n",
        "lgbm_preds = lgbm.predict(X_test_df.iloc[uncertain_indices])\n",
        "infer_time_lgbm = time.time() - start_infer_lgbm\n",
        "\n",
        "# Combine predictions\n",
        "final_predictions = catboost_pred.copy()\n",
        "final_predictions[uncertain_indices] = lgbm_preds\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "f1 = f1_score(y_test, final_predictions, average='weighted')\n",
        "precision = precision_score(y_test, final_predictions, average='weighted')\n",
        "recall = recall_score(y_test, final_predictions, average='weighted')\n",
        "\n",
        "# Total training and inference times\n",
        "total_train_time = train_time_cat + train_time_lgbm\n",
        "total_infer_time = infer_time_cat + infer_time_lgbm\n",
        "\n",
        "# Initialize or append to metrics DataFrame\n",
        "metrics_sbtsk3 = pd.DataFrame(columns=[\"Model Name\", \"Accuracy Score\", \"F1 Score\", \"Precision Score\", \"Recall Score\", \"Training Time (s)\", \"Inference Time (s)\"])\n",
        "\n",
        "new_metrics = pd.DataFrame([{\n",
        "    \"Model Name\": \"CatBoost-LightGBM\",\n",
        "    \"Accuracy Score\": accuracy,\n",
        "    \"F1 Score\": f1,\n",
        "    \"Precision Score\": precision,\n",
        "    \"Recall Score\": recall,\n",
        "    \"Training Time (s)\": round(total_train_time, 4),\n",
        "    \"Inference Time (s)\": round(total_infer_time, 4)\n",
        "}])\n",
        "\n",
        "metrics_sbtsk3 = pd.concat([metrics_sbtsk3, new_metrics], ignore_index=True)\n",
        "\n",
        "metrics_sbtsk3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEIgunr785Di"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Final",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
